{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User-defined prior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyunfold import iterative_unfold\n",
    "from pyunfold.callbacks import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 16.0\n",
    "mpl.rcParams['axes.labelsize'] = 16.0\n",
    "mpl.rcParams['axes.titlesize'] = 14.0\n",
    "mpl.rcParams['legend.fontsize'] = 12.0\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example dataset\n",
    "\n",
    "We'll generate the same example dataset that is used in the [Getting Started tutorial](tutorial.ipynb), i.e. a Gaussian sample that is smeared by some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True distribution\n",
    "num_samples = int(1e5)\n",
    "true_samples = np.random.normal(loc=10.0, scale=4.0, size=num_samples)\n",
    "bins = np.linspace(0, 20, 21)\n",
    "num_causes = len(bins) - 1\n",
    "data_true, _ = np.histogram(true_samples, bins=bins)\n",
    "\n",
    "# Observed distribution\n",
    "random_noise = np.random.normal(loc=0.3, scale=0.5, size=num_samples)\n",
    "observed_samples = true_samples + random_noise\n",
    "data_observed, _ = np.histogram(observed_samples, bins=bins)\n",
    "data_observed_err = np.sqrt(data_observed)\n",
    "\n",
    "# Efficiencies\n",
    "efficiencies = np.ones_like(data_observed, dtype=float)\n",
    "efficiencies_err = np.full_like(efficiencies, 0.1, dtype=float)\n",
    "\n",
    "# Response matrix\n",
    "response_hist, _, _ = np.histogram2d(observed_samples, true_samples, bins=bins)\n",
    "response_hist_err = np.sqrt(response_hist)\n",
    "\n",
    "# Normalized response\n",
    "column_sums = response_hist.sum(axis=0)\n",
    "normalization_factor = efficiencies / column_sums\n",
    "\n",
    "response = response_hist * normalization_factor\n",
    "response_err = response_hist_err * normalization_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what the true and observed distributions look like for this example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.step(np.arange(len(data_true)), data_true, where='mid', lw=3,\n",
    "        alpha=0.7, label='True distribution')\n",
    "ax.step(np.arange(len(data_observed)), data_observed, where='mid', lw=3,\n",
    "        alpha=0.7, label='Observed distribution')\n",
    "ax.set(xlabel='Cause bins', ylabel='Counts')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as the normalized response matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(response, origin='lower')\n",
    "cbar = plt.colorbar(im, label='$P(E_i|C_{\\mu})$')\n",
    "ax.set(xlabel='Cause bins', ylabel='Effect bins',\n",
    "       title='Normalized response matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Priors\n",
    "\n",
    "The default initial prior used in PyUnfold is the uniform prior (i.e. each cause bin is given an equal weighting). We can test other priors by providing a normalized distribution via the `prior` parameter in the `iterative_unfold` function. \n",
    "\n",
    "Several convenience functions for calculating commonly used prior distributions exist in the `pyunfold.priors` module. However, _any_ normalized array-like object (i.e. the items sum to 1) can be passed to `prior` and used as the initial prior in an unfolding. \n",
    "\n",
    "One commonly used prior is the non-informative Jeffreys' prior. The analytic form of this prior is given by \n",
    "\n",
    "$$\n",
    "P(C_{\\mu})^{\\text{Jeffreys}} = \\frac{1}{\\log \\left( C_{\\text{max}} / C_{\\text{min}}\\right) \\, C_{\\mu}}\n",
    "$$\n",
    "\n",
    "where $C_{\\text{max}}$ and $C_{\\text{min}}$ are the maximum and minimum possible cause values, and $C_{\\mu}$ is the value of the $\\mu$th cause bin. Here we'll assume that the cause range covers three orders of magnitude, that is $C_{\\mu} \\in [1, 10^3]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyunfold.priors import jeffreys_prior, uniform_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cause limits\n",
    "cause_lim = np.logspace(0, 3, num_causes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform and Jeffreys' priors\n",
    "uni_prior = uniform_prior(num_causes)\n",
    "jeff_prior = jeffreys_prior(cause_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `uniform_prior` and `jeffreys_prior` functions calculate their corresponding prior distributions and return NumPy `ndarrays` containing these distributions. For more information about these functions, see the [priors API documentation](../api.rst#priors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(uni_prior))\n",
    "print('uni_prior = {}'.format(uni_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(jeff_prior))\n",
    "print('jeff_prior = {}'.format(jeff_prior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.step(cause_lim, jeff_prior, where='mid', lw=3,\n",
    "        alpha=0.7, label='Jeffreys')\n",
    "ax.step(cause_lim, uni_prior, where='mid', lw=3,\n",
    "        alpha=0.7, label='Uniform')\n",
    "ax.set(xlabel='Cause Values $C_{\\mu}$', ylabel='$P(C_{\\mu})$',\n",
    "       title='Priors')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unfolding\n",
    "\n",
    "Now we can run the unfolding with the Jeffreys' prior and compare to the default uniform prior as well as the true cause distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Running with uniform prior...')\n",
    "unfolded_uniform = iterative_unfold(data=data_observed,\n",
    "                                    data_err=data_observed_err,\n",
    "                                    response=response,\n",
    "                                    response_err=response_err,\n",
    "                                    efficiencies=efficiencies,\n",
    "                                    efficiencies_err=efficiencies_err,\n",
    "                                    ts='ks',\n",
    "                                    ts_stopping=0.01,\n",
    "                                    callbacks=[Logger()])\n",
    "\n",
    "print('\\nRunning with Jeffreys prior...')\n",
    "unfolded_jeffreys = iterative_unfold(data=data_observed,\n",
    "                                     data_err=data_observed_err,\n",
    "                                     response=response,\n",
    "                                     response_err=response_err,\n",
    "                                     efficiencies=efficiencies,\n",
    "                                     efficiencies_err=efficiencies_err,\n",
    "                                     prior=jeff_prior,\n",
    "                                     ts='ks',\n",
    "                                     ts_stopping=0.01,\n",
    "                                     callbacks=[Logger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_midpoints = (bins[1:] + bins[:-1]) / 2\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.hist(true_samples, bins=bins, histtype='step', lw=3,\n",
    "        alpha=0.7,\n",
    "        label='True distribution')\n",
    "\n",
    "ax.errorbar(bin_midpoints, unfolded_uniform['unfolded'],\n",
    "            yerr=unfolded_uniform['sys_err'],\n",
    "            alpha=0.7,\n",
    "            elinewidth=3,\n",
    "            capsize=4,\n",
    "            ls='None', marker='.', ms=10, \n",
    "            label='Unfolded - Uniform Prior')\n",
    "\n",
    "ax.errorbar(bin_midpoints, unfolded_jeffreys['unfolded'],\n",
    "            yerr=unfolded_jeffreys['sys_err'],\n",
    "            alpha=0.7,\n",
    "            elinewidth=3,\n",
    "            capsize=4,\n",
    "            ls='None', marker='.', ms=10, \n",
    "            label='Unfolded - Jeffreys Prior')\n",
    "\n",
    "ax.set(xlabel='Cause bins', ylabel='Counts')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unfolded distributions are consistent with each other as well as with the true distribution!\n",
    "Thus, our results are robust with respect to these two **smooth** initial priors.\n",
    "\n",
    "For information about how un-smooth priors can affect an unfolding see the [smoothing via spline regularization example](regularization.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
