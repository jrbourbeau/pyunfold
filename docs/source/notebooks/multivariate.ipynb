{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate unfolding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyunfold import iterative_unfold\n",
    "from pyunfold.callbacks import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.size'] = 16.0\n",
    "mpl.rcParams['axes.labelsize'] = 16.0\n",
    "mpl.rcParams['axes.titlesize'] = 14.0\n",
    "mpl.rcParams['legend.fontsize'] = 12.0\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example dataset\n",
    "\n",
    "We'll generate the same example dataset that is used in the [Getting Started tutorial](tutorial.ipynb), i.e. a Gaussian sample that is smeared by some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True distribution\n",
    "num_samples = int(1e5)\n",
    "true_samples = np.random.normal(loc=10.0, scale=4.0, size=num_samples)\n",
    "bins = np.linspace(0, 20, 21)\n",
    "num_causes = len(bins) - 1\n",
    "data_true, _ = np.histogram(true_samples, bins=bins)\n",
    "\n",
    "# Observed distribution\n",
    "random_noise = np.random.normal(loc=0.3, scale=0.5, size=num_samples)\n",
    "observed_samples = true_samples + random_noise\n",
    "data_observed, _ = np.histogram(observed_samples, bins=bins)\n",
    "data_observed_err = np.sqrt(data_observed)\n",
    "\n",
    "# Efficiencies\n",
    "efficiencies = np.ones_like(data_observed, dtype=float)\n",
    "efficiencies_err = np.full_like(efficiencies, 0.1, dtype=float)\n",
    "\n",
    "# Response matrix\n",
    "response_hist, _, _ = np.histogram2d(observed_samples, true_samples, bins=bins)\n",
    "response_hist_err = np.sqrt(response_hist)\n",
    "\n",
    "# Normalized response\n",
    "column_sums = response_hist.sum(axis=0)\n",
    "normalization_factor = efficiencies / column_sums\n",
    "\n",
    "response = response_hist * normalization_factor\n",
    "response_err = response_hist_err * normalization_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what the true and observed distributions look like for this example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.step(np.arange(len(data_true)), data_true, where='mid', lw=3,\n",
    "        alpha=0.7, label='True distribution')\n",
    "ax.step(np.arange(len(data_observed)), data_observed, where='mid', lw=3,\n",
    "        alpha=0.7, label='Observed distribution')\n",
    "ax.set(xlabel='Cause bins', ylabel='Counts')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as the normalized response matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(response, origin='lower')\n",
    "cbar = plt.colorbar(im, label='$P(E_i|C_{\\mu})$')\n",
    "ax.set(xlabel='Cause bins', ylabel='Effect bins',\n",
    "       title='Normalized response matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cause Groups\n",
    "\n",
    "To illustrate the generalization to multivariate unfolding, we consider a set of effects originating from two different **cause types** having their own ranges. We can assign a new superscript $i$ to denote these types: \n",
    "\n",
    "$$\n",
    "C_{\\mu}^{i} \\text{ where } i \\in [1,2]\n",
    "$$\n",
    "\n",
    "and the subscript $\\mu$ runs over the respective number of causes in each type $\\, n_{C1}$ and $\\, n_{C2}$.\n",
    "\n",
    "But since the PyUnfold doesn't care how we label the bins, we can simply redefine our cause index $\\mu$ to run over a larger index range. Hence, \n",
    "\n",
    "$$\n",
    "C_{\\mu}^i \\rightarrow C_{\\mu} \\text{ where } \\mu \\in [1, \\, n_{C1} + n_{C2}]\n",
    "$$\n",
    "\n",
    "Thus, given a general multidimensional ($i>1$) response matrix, we can effectively *unroll* it onto a two dimensional array and still use PyUnfold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example&mdash;two identical cause groups\n",
    "\n",
    "Here we use two identical cause groups, simply copying our original response matrix along the cause axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response with two groups\n",
    "response_hist_groups = np.concatenate((response_hist, response_hist), axis=1)\n",
    "response_hist_groups_err = np.sqrt(response_hist_groups)\n",
    "\n",
    "# Efficiencies with two groups\n",
    "efficiencies_groups = np.ones(response_hist_groups.shape[1], dtype=float)\n",
    "efficiencies_groups_err = np.full_like(efficiencies_groups, 0.1, dtype=float)\n",
    "num_causes = response_hist_groups.shape[1]\n",
    "\n",
    "# Scale by efficiency\n",
    "column_sums_groups = response_hist_groups.sum(axis=0)\n",
    "normalization_factor_groups = efficiencies_groups / column_sums_groups\n",
    "\n",
    "# Response matrix with two groups\n",
    "response_groups = response_hist_groups * normalization_factor_groups\n",
    "response_groups_err = response_hist_groups_err * normalization_factor_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "im = ax.imshow(response_groups, origin='lower')\n",
    "plt.colorbar(im, label='$P(E_i|C_{\\mu})$')\n",
    "ax.set(xlabel='Cause bins', ylabel='Effect bins',\n",
    "       title='Normalized response matrix - 2 groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the two (identical) cause groups are *unrolled* clearly along the abscissa. Since the unfolding method is cause agnostic, we can perform an unfolding, remembering that we've kept the same observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolded_results_groups = iterative_unfold(data=data_observed,\n",
    "                                           data_err=data_observed_err,\n",
    "                                           response=response_groups,\n",
    "                                           response_err=response_groups_err,\n",
    "                                           efficiencies=efficiencies_groups,\n",
    "                                           efficiencies_err=efficiencies_groups_err,\n",
    "                                           ts='ks',\n",
    "                                           ts_stopping=0.01,\n",
    "                                           callbacks=[Logger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.errorbar(np.arange(num_causes), unfolded_results_groups['unfolded'],\n",
    "            yerr=unfolded_results_groups['sys_err'],\n",
    "            alpha=0.7,\n",
    "            elinewidth=3,\n",
    "            capsize=4,\n",
    "            ls='None', marker='.', ms=10)\n",
    "ax.set(xlabel='Cause bins', ylabel='Counts',\n",
    "        title='Group Unfolding')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the result is two equal copies of the causes. This makes sense because in our example we have simply considered two *identical* groups of causes, so they should contribute identically to producing the measured effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Priors with Groups\n",
    "\n",
    "What if we want to use the a user-defined prior (e.g. Jeffreys' prior)? In this case, we have to setup the `prior` input to contain the priors we want for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyunfold.priors import jeffreys_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cause limits\n",
    "cause_lim = np.logspace(0, 3, num_causes//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup group Jeffreys' prior\n",
    "prior_jeff_groups = np.concatenate([jeffreys_prior(cause_lim), jeffreys_prior(cause_lim)])\n",
    "prior_jeff_groups = prior_jeff_groups / prior_jeff_groups.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.step(np.arange(num_causes), prior_jeff_groups, where='mid', lw=3,\n",
    "        alpha=0.8)\n",
    "ax.set(xlabel='Cause bins', ylabel='$P(C_{\\mu})$',\n",
    "       title='Group Jeffreys Priors')\n",
    "ax.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolded_results_groups_jeff = iterative_unfold(data=data_observed,\n",
    "                                                data_err=data_observed_err,\n",
    "                                                response=response_groups,\n",
    "                                                response_err=response_groups_err,\n",
    "                                                efficiencies=efficiencies_groups,\n",
    "                                                efficiencies_err=efficiencies_groups_err,\n",
    "                                                prior=prior_jeff_groups,\n",
    "                                                ts='ks',\n",
    "                                                ts_stopping=0.01,\n",
    "                                                callbacks=[Logger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "plt.errorbar(np.arange(num_causes), unfolded_results_groups_jeff['unfolded'],\n",
    "             yerr=unfolded_results_groups_jeff['sys_err'],\n",
    "             alpha=0.7,\n",
    "             elinewidth=3,\n",
    "             capsize=4,\n",
    "             ls='None', marker='.', ms=10)\n",
    "\n",
    "ax.set(xlabel='Cause bins', ylabel='Counts',\n",
    "       title='Group Unfolding - Jeffreys Prior')\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we recover two copies of the causes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization with Groups\n",
    "\n",
    "In general, groups of causes do not share continuity of the cause axis. \n",
    "In the above examples, the cause arrays are stacked next to each other, so while the unfolding method doesn't care about the cause definitions, the default regularization smooths over **all** cause bins without regard to types.\n",
    "\n",
    "PyUnfold implements group regularization, where smoothing of the unfolded distributions is performed only within designated cause types (i.e. each cause type is regularized independently).\n",
    "This is done by providing the `SplineRegularizer` function a `groups` list, defining a group identification for each cause bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyunfold.callbacks import SplineRegularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we know we have two copies of the causes\n",
    "n_c1 = response_groups.shape[1] // 2\n",
    "n_c2 = response_groups.shape[1] // 2\n",
    "\n",
    "groups = [0]*n_c1 + [1]*n_c2\n",
    "print(\"Group definitions: \\n{}\".format(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_reg = SplineRegularizer(degree=3, smooth=1.25, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolded_results_groups_reg = iterative_unfold(data=data_observed,\n",
    "                                               data_err=data_observed_err,\n",
    "                                               response=response_groups,\n",
    "                                               response_err=response_groups_err,\n",
    "                                               efficiencies=efficiencies_groups,\n",
    "                                               efficiencies_err=efficiencies_groups_err,\n",
    "                                               ts='ks',\n",
    "                                               ts_stopping=0.01,\n",
    "                                               callbacks=[Logger(), group_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.errorbar(np.arange(num_causes), unfolded_results_groups_reg['unfolded'],\n",
    "            yerr=unfolded_results_groups_reg['sys_err'],\n",
    "            alpha=0.7,\n",
    "            elinewidth=3,\n",
    "            capsize=4,\n",
    "            ls='None', marker='.', ms=10)\n",
    "\n",
    "ax.set(xlabel='Cause bins', ylabel='Counts',\n",
    "       title='Group Unfolding - regularized')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, for this simple example, everything looks fine.\n",
    "\n",
    "However, if we consider a more complicated example, we'll see the power of these implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitfalls of multivariate unfolding\n",
    "\n",
    "Let's generate some more example data by keeping our two-type response matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True distribution\n",
    "group_data_true = np.concatenate((np.linspace(10, 100, n_c1), np.linspace(1, 10, n_c2)))\n",
    "\n",
    "# Observed data, no smearing\n",
    "group_data_observed = response_groups.dot(group_data_true)\n",
    "group_data_observed_err = np.sqrt(group_data_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax_1, ax_2) = plt.subplots(ncols=2, figsize=(20, 8))\n",
    "# Cause distribution\n",
    "ax_1.step(np.arange(num_causes), group_data_true, where='mid', lw=3,\n",
    "         alpha=0.7, label='True distribution')\n",
    "ax_1.set(xlabel='Cause bins', ylabel='Counts', \n",
    "         title='Cause Distribution')\n",
    "\n",
    "# Effects distribution\n",
    "ax_2.step(np.arange(len(group_data_observed)), group_data_observed, where='mid', lw=3,\n",
    "          alpha=0.7, label='Observed distribution')\n",
    "ax_2.set(xlabel='Effect bins', ylabel='Counts', \n",
    "         title='Effects Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup all cause spline\n",
    "spline_reg = SplineRegularizer(degree=3, smooth=5e6)\n",
    "\n",
    "# Setup group spline\n",
    "group_reg = SplineRegularizer(degree=3, smooth=1.25, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolded_results_groups_default_reg = iterative_unfold(data=group_data_observed,\n",
    "                                                       data_err=group_data_observed_err,\n",
    "                                                       response=response_groups,\n",
    "                                                       response_err=response_groups_err,\n",
    "                                                       efficiencies=efficiencies_groups,\n",
    "                                                       efficiencies_err=efficiencies_groups_err,\n",
    "                                                       ts='ks',\n",
    "                                                       ts_stopping=0.01,\n",
    "                                                       callbacks=[Logger(), spline_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolded_results_groups_group_reg = iterative_unfold(data=group_data_observed,\n",
    "                                                     data_err=group_data_observed_err,\n",
    "                                                     response=response_groups,\n",
    "                                                     response_err=response_groups_err,\n",
    "                                                     efficiencies=efficiencies_groups,\n",
    "                                                     efficiencies_err=efficiencies_groups_err,\n",
    "                                                     ts='ks',\n",
    "                                                     ts_stopping=0.01,\n",
    "                                                     callbacks=[Logger(), group_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.step(np.arange(num_causes), group_data_true, where='mid', lw=3,\n",
    "        alpha=0.7, label='True Distribution')\n",
    "\n",
    "ax.errorbar(np.arange(num_causes), unfolded_results_groups_group_reg['unfolded'],\n",
    "            yerr=unfolded_results_groups_group_reg['sys_err'],\n",
    "            alpha=0.7,\n",
    "            elinewidth=3,\n",
    "            capsize=4,\n",
    "            ls='None', marker='.', ms=10,\n",
    "            label='Group Regularization')\n",
    "\n",
    "ax.errorbar(np.arange(num_causes), unfolded_results_groups_default_reg['unfolded'],\n",
    "            yerr=unfolded_results_groups_default_reg['sys_err'],\n",
    "            alpha=0.7,\n",
    "            elinewidth=3,\n",
    "            capsize=4,\n",
    "            ls='None', marker='.', ms=10,\n",
    "            label='Default Regularization')\n",
    "\n",
    "ax.set(xlabel='Cause bins', ylabel='Counts',\n",
    "       title='Group Unfolding')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what's going on here? There are actually two problems here. \n",
    "\n",
    "1. It's clear that the default regularization tries to connect the two cause groups in a smooth manner.\n",
    "2. And while the group regularization is doing its best to smooth each group individually, it's clear we are getting copies again. This is due to the **prior** assumption that all causes have equal probabilities.\n",
    "\n",
    "Let's redo this by giving a strong preference in the prior to one of the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flat prior to each group, but one has stronger preference.\n",
    "flat_pref_prior = np.concatenate((8.*np.ones(n_c1), np.ones(n_c1)))\n",
    "flat_pref_prior = flat_pref_prior / flat_pref_prior.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolded_results_groups_group_reg_prior = iterative_unfold(data=group_data_observed,\n",
    "                                                           data_err=group_data_observed_err,\n",
    "                                                           response=response_groups,\n",
    "                                                           response_err=response_groups_err,\n",
    "                                                           efficiencies=efficiencies_groups,\n",
    "                                                           efficiencies_err=efficiencies_groups_err,\n",
    "                                                           prior=flat_pref_prior,\n",
    "                                                           ts='ks',\n",
    "                                                           ts_stopping=0.01,\n",
    "                                                           callbacks=[Logger(), group_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.step(np.arange(num_causes), group_data_true, where='mid', lw=3,\n",
    "        alpha=0.7, label='True Distribution')\n",
    "\n",
    "ax.errorbar(np.arange(num_causes), unfolded_results_groups_group_reg_prior['unfolded'],\n",
    "            yerr=unfolded_results_groups_group_reg_prior['sys_err'],\n",
    "            alpha=0.7,\n",
    "            elinewidth=3,\n",
    "            capsize=4,\n",
    "            ls='None', marker='.', ms=10,\n",
    "            label='Group Regularization')\n",
    "\n",
    "ax.set(xlabel='Cause bins', ylabel='Counts',\n",
    "       title='Group Unfolding')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're starting to get something that looks right.\n",
    "\n",
    "However, we are still using two identical copies of the response matrix which means that we're considering the same sets of causes, just split up into two groups.\n",
    "\n",
    "This also demonstrates another potential issue with doing group unfolding: if there is high degree of degeneracy between the respective response functions, then the unfolding results will be strongly dependent on intial priors.\n",
    "\n",
    "The solution to this is to ensure that the cause group response matrices have different structure, for example by having different normalizations (efficiency). We demonstrate this below to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response with two groups having different structures\n",
    "n_c1 = len(response_hist)\n",
    "n_c2 = 5\n",
    "response_hist_groups = np.concatenate((response_hist, response_hist[:,0:n_c2]), axis=1)\n",
    "response_hist_groups_err = np.sqrt(response_hist_groups)\n",
    "\n",
    "# Efficiencies with two groups\n",
    "efficiencies_groups = np.ones(response_hist_groups.shape[1], dtype=float)\n",
    "efficiencies_groups_err = np.full_like(efficiencies_groups, 0.1, dtype=float)\n",
    "# Make the second group 25% efficient\n",
    "efficiencies_groups[0:n_c1] *= 1\n",
    "efficiencies_groups[n_c1:-1] *= 0.25\n",
    "efficiencies_groups_err = np.full_like(efficiencies_groups, 0.1, dtype=float)\n",
    "\n",
    "# Scale by efficiency\n",
    "column_sums_groups = response_hist_groups.sum(axis=0)\n",
    "normalization_factor_groups = efficiencies_groups / column_sums_groups\n",
    "\n",
    "# Response matrix with two groups\n",
    "response_groups = response_hist_groups * normalization_factor_groups\n",
    "response_groups_err = response_hist_groups_err * normalization_factor_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [0]*n_c1 + [1]*n_c2\n",
    "print(\"Group definitions: {}\".format(groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_reg = SplineRegularizer(degree=3, smooth=1.25, groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "im = ax.imshow(response_groups, origin='lower')\n",
    "plt.colorbar(im, label='$P(E_i|C_{\\mu})$')\n",
    "ax.set(xlabel='Cause bins', ylabel='Effect bins',\n",
    "       title='Normalized response matrix - groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regenerate some example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True distribution\n",
    "group_data_true = np.concatenate((np.linspace(10, 100, n_c1), np.linspace(1, 10, n_c2)))\n",
    "num_causes = len(group_data_true)\n",
    "\n",
    "# Observed data, no smearing\n",
    "group_data_observed = response_groups.dot(group_data_true)\n",
    "group_data_observed_err = np.sqrt(group_data_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolded_results_groups_group_reg = iterative_unfold(data=group_data_observed,\n",
    "                                                     data_err=group_data_observed_err,\n",
    "                                                     response=response_groups,\n",
    "                                                     response_err=response_groups_err,\n",
    "                                                     efficiencies=efficiencies_groups,\n",
    "                                                     efficiencies_err=efficiencies_groups_err,\n",
    "                                                     ts='ks',\n",
    "                                                     ts_stopping=0.01,\n",
    "                                                     callbacks=[Logger(), group_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend range of bins\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.step(np.arange(num_causes), group_data_true, where='mid', lw=3,\n",
    "        alpha=0.7, label='True Distribution')\n",
    "\n",
    "ax.errorbar(np.arange(num_causes), unfolded_results_groups_group_reg['unfolded'],\n",
    "            yerr=unfolded_results_groups_group_reg['sys_err'],\n",
    "            alpha=0.7,\n",
    "            elinewidth=3,\n",
    "            capsize=4,\n",
    "            ls='None', marker='.', ms=10,\n",
    "            label='Group Regularization')\n",
    "\n",
    "ax.set(xlabel='Cause bins', ylabel='Counts',\n",
    "       title='Group Unfolding')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the groups are differentiable in terms of response structure and efficiencies, we obtain reasonable unfolding results even using the default uniform prior across all bins!\n",
    "\n",
    "This simply illustrates the need for proper understanding of one's data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
